beta1 <- 4 + 2 * Wmat[,1] + 2 * Wmat[,2] + 2 * Wmat[,5]
beta0 <- 2 + 2 * Wmat[,1] + 2 * Wmat[,2] + 2 * Wmat[,5]
tau <- 2  # true effect
gcoef <- matrix(c(-1, -1, rep(-(3/((p) - 2)),(p) - 2)),ncol=1)
rep(-(3/((p) - 2))
rep(-(3/((p) - 2)), (p) - 2)
rep(-(3/((p) - 2)), (p) - 2))
(3/((p) - 2))
-(3/((p) - 2))
rep(-(3/((p) - 2)), (p) - 2)
library(ctmle)
library(dplyr)
### simulate dataset
rm(list=ls())
set.seed(123)
N <- 1000
p = 5
Wmat <- matrix(rnorm(N * p), ncol = p) # 5 variables baselines normales, indépendantes
head(Wmat)
#             [,1]        [,2]       [,3]        [,4]       [,5]
# [1,] -0.56047565 -0.99579872 -0.5116037 -0.15030748  0.1965498
# [2,] -0.23017749 -1.03995504  0.2369379 -0.32775713  0.6501132
# [3,]  1.55870831 -0.01798024 -0.5415892 -1.44816529  0.6710042
# [4,]  0.07050839 -0.13217513  1.2192276 -0.69728458 -1.2841578
# [5,]  0.12928774 -2.54934277  0.1741359  2.59849023 -2.0261096
# [6,]  1.71506499  1.04057346 -0.6152683 -0.03741501  2.2053261
beta1 <- 4 + 2 * Wmat[,1] + 2 * Wmat[,2] + 2 * Wmat[,5]
beta0 <- 2 + 2 * Wmat[,1] + 2 * Wmat[,2] + 2 * Wmat[,5]
tau <- 2  # true effect
gcoef <- matrix(c(-1, -1, rep(-(3/((p) - 2)), (p) - 2) ), ncol=1)
#      [,1]
# [1,]   -1
# [2,]   -1
# [3,]   -1
# [4,]   -1
# [5,]   -1
W <- as.matrix(Wmat)
# g()
g <- 1 / (1 + exp( W %*% gcoef / 3) ) # probabilité prédite par un modèle logistique où chaque W a un coefficient égale à -1/3 et un intercept = 0
A <- rbinom(N, 1, prob = g)
epsilon <-rnorm(N, 0, 1)
# Q_bar
Y  <- beta0 + tau * A + epsilon
# With initial estimate of Q = la valeur de Y chez les individus exposés au niveau d'intérêt : A=0 ou A=1
Q <- cbind(rep(mean(Y[A == 0]), N),
rep(mean(Y[A == 1]), N))
time_greedy <- system.time(
ctmle_discrete_fit1 <- ctmleDiscrete(Y = Y,
A = A,
W = data.frame(Wmat),
Q = Q,
preOrder = FALSE, # greedy
detailed = TRUE)
)
ctmle_discrete_fit2 <- ctmleDiscrete(Y = Y, A = A, W = data.frame(Wmat),
preOrder = FALSE, detailed = TRUE)
### simulate dataset
rm(list=ls())
set.seed(123)
N <- 1000
p = 5
Wmat <- matrix(rnorm(N * p), ncol = p) # 5 variables baselines normales, indépendantes
head(Wmat)
#             [,1]        [,2]       [,3]        [,4]       [,5]
# [1,] -0.56047565 -0.99579872 -0.5116037 -0.15030748  0.1965498
# [2,] -0.23017749 -1.03995504  0.2369379 -0.32775713  0.6501132
# [3,]  1.55870831 -0.01798024 -0.5415892 -1.44816529  0.6710042
# [4,]  0.07050839 -0.13217513  1.2192276 -0.69728458 -1.2841578
# [5,]  0.12928774 -2.54934277  0.1741359  2.59849023 -2.0261096
# [6,]  1.71506499  1.04057346 -0.6152683 -0.03741501  2.2053261
beta1 <- 4 + 2 * Wmat[,1] + 2 * Wmat[,2] + 2 * Wmat[,5]
beta0 <- 2 + 2 * Wmat[,1] + 2 * Wmat[,2] + 2 * Wmat[,5]
tau <- 2  # true effect
gcoef <- matrix(c(-1, -1, rep(-(3/((p) - 2)), (p) - 2) ), ncol=1)
#      [,1]
# [1,]   -1
# [2,]   -1
# [3,]   -1
# [4,]   -1
# [5,]   -1
W <- as.matrix(Wmat)
# g()
g <- 1 / (1 + exp( W %*% gcoef / 3) ) # probabilité prédite par un modèle logistique où chaque W a un coefficient égale à -1/3 et un intercept = 0
A <- rbinom(N, 1, prob = g)
epsilon <-rnorm(N, 0, 1)
# Q_bar
Y  <- beta0 + tau * A + epsilon
# With initial estimate of Q = la valeur de Y chez les individus exposés au niveau d'intérêt : A=0 ou A=1
Q <- cbind(rep(mean(Y[A == 0]), N),
rep(mean(Y[A == 1]), N))
time_greedy <- system.time(
ctmle_discrete_fit1 <- ctmleDiscrete(Y = Y,
A = A,
W = data.frame(Wmat),
Q = Q, # nx2 matrix of initial values for Q0W, Q1W in columns 1 and 2 respectively. Current version does not support SL for automatic initial estimation of Q bar
preOrder = FALSE, # greedy
detailed = TRUE)
)
ctmle_discrete_fit2 <- ctmleDiscrete(Y = Y, # ici, on ne précise pas la initial estimate of Q ??
A = A,
W = data.frame(Wmat),
preOrder = FALSE, # greedy,
detailed = TRUE)
time_preorder <- system.time(
ctmle_discrete_fit3 <- ctmleDiscrete(Y = Y,
A = A,
W = data.frame(Wmat),
Q = Q,
preOrder = TRUE, # use scalable C-TMLE
order = rev(1:p),
detailed = TRUE)
)
time_greedy
time_preorder
ctmle_discrete_fit1
summary(ctmle_discrete_fit1)
summary(ctmle_discrete_fit2)
summary(ctmle_discrete_fit3)
set.seed(123)
N <- 1000
p = 100
Wmat <- matrix(rnorm(N * p), ncol = p)
beta1 <- 4+2*Wmat[,1]+2*Wmat[,2]+2*Wmat[,5]+2*Wmat[,6]+2*Wmat[,8]
beta0 <- 2+2*Wmat[,1]+2*Wmat[,2]+2*Wmat[,5]+2*Wmat[,6]+2*Wmat[,8]
tau <- 2
gcoef <- matrix(c(-1,-1,rep(-(3/((p)-2)),(p)-2)),ncol=1)
W <- as.matrix(Wmat)
g <- 1/(1+exp(W%*%gcoef /3))
A <- rbinom(N, 1, prob = g)
epsilon <-rnorm(N, 0, 1)
Y  <- beta0 + tau * A + epsilon
# With initial estimate of Q
Q <- cbind(rep(mean(Y[A == 0]), N),
rep(mean(Y[A == 1]), N))
glmnet_fit <- cv.glmnet(y = A, # fonction g
x = W,
family = 'binomial',
nlambda = 20)
glmnet_fit
glmnet_fit$lambda
glmnet_fit$glmnet.fit
set.seed(123)
N <- 1000
p = 100
Wmat <- matrix(rnorm(N * p), ncol = p)
beta1 <- 4+2*Wmat[,1]+2*Wmat[,2]+2*Wmat[,5]+2*Wmat[,6]+2*Wmat[,8]
beta0 <- 2+2*Wmat[,1]+2*Wmat[,2]+2*Wmat[,5]+2*Wmat[,6]+2*Wmat[,8]
tau <- 2
gcoef <- matrix(c(-1,-1,rep(-(3/((p)-2)),(p)-2)),ncol=1)
W <- as.matrix(Wmat)
g <- 1/(1+exp(W%*%gcoef /3))
A <- rbinom(N, 1, prob = g)
epsilon <-rnorm(N, 0, 1)
Y  <- beta0 + tau * A + epsilon
# With initial estimate of Q
Q <- cbind(rep(mean(Y[A == 0]), N),
rep(mean(Y[A == 1]), N))
glmnet_fit <- cv.glmnet(y = A, # fonction g régression logistique lasso
x = W,
family = 'binomial',
nlambda = 20)
# We suggest start build a sequence of lambdas from the lambda selected by cross-validation,
# as the model selected by cv.glmnet would over-smooth w.r.t. the target parameter.
lambdas <-glmnet_fit$lambda[(which(glmnet_fit$lambda==glmnet_fit$lambda.min)):length(glmnet_fit$lambda)]
# We fit C-TMLE1 algorithm by feed the algorithm with a vector of lambda, in decreasing order:
time_ctmlelasso1 <- system.time(
ctmle_fit1 <- ctmleGlmnet(Y = Y,
A = A,
W = data.frame(W = W),
Q = Q,
lambdas = lambdas,
ctmletype=1,
family="gaussian",
gbound=0.025,
V=5)
)
# We fit C-TMLE2 algorithm
time_ctmlelasso2 <- system.time(
ctmle_fit2 <- ctmleGlmnet(Y = Y,
A = A,
W = data.frame(W = W),
Q = Q,
lambdas = lambdas,
ctmletype=2,
family="gaussian",
gbound=0.025,
V=5)
)
# For C-TMLE3, we need two gn estimators, one with lambda selected by cross-validation,
# and the other with lambda slightly different from the selected lambda
gcv <- stats::predict(glmnet_fit, newx=W, s="lambda.min",type="response")
gcv <- bound(gcv,c(0.025,0.975))
s_prev <- glmnet_fit$lambda[(which(glmnet_fit$lambda == glmnet_fit$lambda.min))] * (1+5e-2)
gcvPrev <- stats::predict(glmnet_fit,newx = W,s = s_prev,type="response")
gcvPrev <- bound(gcvPrev,c(0.025,0.975))
time_ctmlelasso3 <- system.time(
ctmle_fit3 <- ctmleGlmnet(Y = Y, A = A, W = W, Q = Q,
ctmletype=3, g1W = gcv, g1WPrev = gcvPrev,
family="gaussian",
gbound=0.025, V = 5)
)
# Les't compare the running time for each LASSO-C-TMLE
time_ctmlelasso1
time_ctmlelasso2
time_ctmlelasso3
ctmle_fit1
ctmle_fit2
ctmle_fit3
lambdas[ctmle_fit1$best_k]
glmnet_fit$lambda.min
devtools::install_github("benoitlepage/MargIntTmle")
packageVersion("devtools")
install.packages(c("attention", "bartMachine", "blob", "bookdown", "broom", "broom.helpers", "cachem", "car", "caret", "checkmate", "classInt", "cli", "commonmark", "data.table", "dbplyr", "DescTools", "dplyr", "dtplyr", "evaluate", "fastmap", "flextable", "fma", "fontawesome", "forecast", "Formula", "fpp2", "fs", "future", "gam", "gargle", "gdtools", "ggdag", "ggplot2", "ggpubr", "ggsci", "gh", "glmnet", "Gmisc", "googledrive", "googlesheets4", "graphlayouts", "gt", "gtable", "gtsummary", "h2o", "hardhat", "haven", "Hmisc", "hms", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "interp", "ipred", "keras", "labelled", "later", "lava", "lme4", "ltmle", "lubridate", "markdown", "MASS", "Matrix", "metafor", "microbenchmark", "modelr", "multcomp", "officer", "openssl", "packrat", "pak", "parallelly", "pillar", "processx", "prodlim", "profvis", "ps", "psych", "quantmod", "quantreg", "ranger", "raster", "RcppArmadillo", "RCurl", "readr", "readxl", "recipes", "rgdal", "rgeos", "rlang", "rmarkdown", "rms", "rnn", "s2", "sass", "sf", "SnowballC", "speedglm", "styler", "survey", "terra", "testthat", "TH.data", "tibble", "tidyverse", "tinytex", "triebeard", "truncnorm", "tseries", "tsfgrnn", "units", "V8", "vctrs", "VGAM", "viridis", "viridisLite", "vroom", "waldo", "wk", "xfun", "xgboost", "XML", "xml2", "xts", "zip", "zoo"))
install.packages(c("attention", "bartMachine", "blob", "bookdown", "broom", "broom.helpers", "cachem", "car", "caret", "checkmate", "classInt", "cli", "commonmark", "data.table", "dbplyr", "DescTools", "dplyr", "dtplyr", "evaluate", "fastmap", "flextable", "fma", "fontawesome", "forecast", "Formula", "fpp2", "fs", "future", "gam", "gargle", "gdtools", "ggdag", "ggplot2", "ggpubr", "ggsci", "gh", "glmnet", "Gmisc", "googledrive", "googlesheets4", "graphlayouts", "gt", "gtable", "gtsummary", "h2o", "hardhat", "haven", "Hmisc", "hms", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "interp", "ipred", "keras", "labelled", "later", "lava", "lme4", "ltmle", "lubridate", "markdown", "MASS", "Matrix", "metafor", "microbenchmark", "modelr", "multcomp", "officer", "openssl", "packrat", "pak", "parallelly", "pillar", "processx", "prodlim", "profvis", "ps", "psych", "quantmod", "quantreg", "ranger", "raster", "RcppArmadillo", "RCurl", "readr", "readxl", "recipes", "rgdal", "rgeos", "rlang", "rmarkdown", "rms", "rnn", "s2", "sass", "sf", "SnowballC", "speedglm", "styler", "survey", "terra", "testthat", "TH.data", "tibble", "tidyverse", "tinytex", "triebeard", "truncnorm", "tseries", "tsfgrnn", "units", "V8", "vctrs", "VGAM", "viridis", "viridisLite", "vroom", "waldo", "wk", "xfun", "xgboost", "XML", "xml2", "xts", "zip", "zoo"))
install.packages(c("attention", "bartMachine", "blob", "bookdown", "broom", "broom.helpers", "cachem", "car", "caret", "checkmate", "classInt", "cli", "commonmark", "data.table", "dbplyr", "DescTools", "dplyr", "dtplyr", "evaluate", "fastmap", "flextable", "fma", "fontawesome", "forecast", "Formula", "fpp2", "fs", "future", "gam", "gargle", "gdtools", "ggdag", "ggplot2", "ggpubr", "ggsci", "gh", "glmnet", "Gmisc", "googledrive", "googlesheets4", "graphlayouts", "gt", "gtable", "gtsummary", "h2o", "hardhat", "haven", "Hmisc", "hms", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "interp", "ipred", "keras", "labelled", "later", "lava", "lme4", "ltmle", "lubridate", "markdown", "MASS", "Matrix", "metafor", "microbenchmark", "modelr", "multcomp", "officer", "openssl", "packrat", "pak", "parallelly", "pillar", "processx", "prodlim", "profvis", "ps", "psych", "quantmod", "quantreg", "ranger", "raster", "RcppArmadillo", "RCurl", "readr", "readxl", "recipes", "rgdal", "rgeos", "rlang", "rmarkdown", "rms", "rnn", "s2", "sass", "sf", "SnowballC", "speedglm", "styler", "survey", "terra", "testthat", "TH.data", "tibble", "tidyverse", "tinytex", "triebeard", "truncnorm", "tseries", "tsfgrnn", "units", "V8", "vctrs", "VGAM", "viridis", "viridisLite", "vroom", "waldo", "wk", "xfun", "xgboost", "XML", "xml2", "xts", "zip", "zoo"))
install.packages(c("attention", "bartMachine", "blob", "bookdown", "broom", "broom.helpers", "cachem", "car", "caret", "checkmate", "classInt", "cli", "commonmark", "data.table", "dbplyr", "DescTools", "dplyr", "dtplyr", "evaluate", "fastmap", "flextable", "fma", "fontawesome", "forecast", "Formula", "fpp2", "fs", "future", "gam", "gargle", "gdtools", "ggdag", "ggplot2", "ggpubr", "ggsci", "gh", "glmnet", "Gmisc", "googledrive", "googlesheets4", "graphlayouts", "gt", "gtable", "gtsummary", "h2o", "hardhat", "haven", "Hmisc", "hms", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "interp", "ipred", "keras", "labelled", "later", "lava", "lme4", "ltmle", "lubridate", "markdown", "MASS", "Matrix", "metafor", "microbenchmark", "modelr", "multcomp", "officer", "openssl", "packrat", "pak", "parallelly", "pillar", "processx", "prodlim", "profvis", "ps", "psych", "quantmod", "quantreg", "ranger", "raster", "RcppArmadillo", "RCurl", "readr", "readxl", "recipes", "rgdal", "rgeos", "rlang", "rmarkdown", "rms", "rnn", "s2", "sass", "sf", "SnowballC", "speedglm", "styler", "survey", "terra", "testthat", "TH.data", "tibble", "tidyverse", "tinytex", "triebeard", "truncnorm", "tseries", "tsfgrnn", "units", "V8", "vctrs", "VGAM", "viridis", "viridisLite", "vroom", "waldo", "wk", "xfun", "xgboost", "XML", "xml2", "xts", "zip", "zoo"))
install.packages(c("attention", "bartMachine", "blob", "bookdown", "broom", "broom.helpers", "cachem", "car", "caret", "checkmate", "classInt", "cli", "commonmark", "data.table", "dbplyr", "DescTools", "dplyr", "dtplyr", "evaluate", "fastmap", "flextable", "fma", "fontawesome", "forecast", "Formula", "fpp2", "fs", "future", "gam", "gargle", "gdtools", "ggdag", "ggplot2", "ggpubr", "ggsci", "gh", "glmnet", "Gmisc", "googledrive", "googlesheets4", "graphlayouts", "gt", "gtable", "gtsummary", "h2o", "hardhat", "haven", "Hmisc", "hms", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "interp", "ipred", "keras", "labelled", "later", "lava", "lme4", "ltmle", "lubridate", "markdown", "MASS", "Matrix", "metafor", "microbenchmark", "modelr", "multcomp", "officer", "openssl", "packrat", "pak", "parallelly", "pillar", "processx", "prodlim", "profvis", "ps", "psych", "quantmod", "quantreg", "ranger", "raster", "RcppArmadillo", "RCurl", "readr", "readxl", "recipes", "rgdal", "rgeos", "rlang", "rmarkdown", "rms", "rnn", "s2", "sass", "sf", "SnowballC", "speedglm", "styler", "survey", "terra", "testthat", "TH.data", "tibble", "tidyverse", "tinytex", "triebeard", "truncnorm", "tseries", "tsfgrnn", "units", "V8", "vctrs", "VGAM", "viridis", "viridisLite", "vroom", "waldo", "wk", "xfun", "xgboost", "XML", "xml2", "xts", "zip", "zoo"))
install.packages(c("cli", "Hmisc", "httpuv", "rlang", "rms"))
install.packages(c("cli", "Hmisc", "httpuv", "rlang", "rms"))
library(devtools)
check()
check()
library(usethis)
edit_r_buildignore()
use_build_ignore(docs)
use_build_ignore("docs")
check()
library(devtools)
load_all()
use_test(def.param.R)
use_r("def.param")
load_all()
test_param <- param.causal.model()
test_param
df <- generate.data(N = 1000, b =  param.causal.model(), Y_type = "binary")
summary(df)
df <- generate.data(N = 1000, b =  param.causal.model(, b_Y = 100, b_L1_Y = 20, b_L2_Y = 20, b_L3_Y = -30, b_A1_Y = 30, b_A2_Y = 10, b_A1A2_Y = 20, se_Y = 20), Y_type = "continuous")
beta <- param.causal.model(b_Y = 100, b_L1_Y = 20, b_L2_Y = 20, b_L3_Y = -30, b_A1_Y = 30, b_A2_Y = 10, b_A1A2_Y = 20, se_Y = 20)
beta <- param.causal.model(b_Y = 100, b_L1_Y = 20, b_L2_Y = 20, b_L3_Y = -30, b_A1_Y = 30, b_A2_Y = 10, b_A1A2_Y = 20, se_Y = 20, Y_type = "continuous")
beta
df <- generate.data(N = 1000, b =  beta, Y_type = "continuous")
summary(df)
library(kableExtra)
?kableExtra::kable
library(devtools)
load_all()
require(MargIntTmle)
set.seed(54321)
df <- generate.data(N = 1000,
b = param.causal.model(Y_type = "continuous",
b_Y = 100, b_L1_Y = 10, b_L2_Y = 30,
b_L3_Y = -20, b_A1_Y = 10, b_A2_Y = 30,
b_A1A2_Y = 20, se_Y = 20),
Y_type = "continuous")
head(df)
summary(df)
require(ltmle)
require(SuperLearner)
# define Q and g formulas following the argument notation of the ltmle package:
Q_formulas = c(hlth.outcome="Q.kplus1 ~ conf1 + conf2 + conf3 + sex * env")
g_formulas = c("sex ~ conf1 + conf2","env ~ conf1 + conf3")
# choose a set of fitting libraries to pass to SuperLearner:
SL.library = list(Q=list("SL.glm"),g=list("SL.glm"))
# apply the int.ltmleMSM function. In order to apply the TMLE and IPTW estimators,
# gcomp argument is set to FALSE.
interaction.ltmle <- int.ltmleMSM(data = df,
Qform = Q_formulas,
gform = g_formulas,
Anodes = c("sex", "env"),
Lnodes = c("conf1", "conf2", "conf3"),
Ynodes = c("hlth.outcome"),
SL.library = SL.library,
gcomp = FALSE,
iptw.only = FALSE,
survivalOutcome = FALSE,
variance.method = "ic")
interaction.ltmle$ltmle_MSM$msm
interaction.ltmle$ltmle_MSM$msm$family
set.seed(54321)
df.cont.Y <- generate.data(N = 1000,
b = param.causal.model(Y_type = "continuous",
b_Y = 100, b_L1_Y = 10, b_L2_Y = 30,
b_L3_Y = -20, b_A1_Y = 10, b_A2_Y = 30,
b_A1A2_Y = 20, se_Y = 20),
Y_type = "continuous")
summary(df.cont.Y)
Q_formulas = c(hlth.outcome="Q.kplus1 ~ conf1 + conf2 + conf3 + sex * env")
g_formulas = c("sex ~ conf1 + conf2","env ~ conf1 + conf3")
# choose a set of fitting libraries to pass to SuperLearner:
SL.library = list(Q=list("SL.glm"),g=list("SL.glm"))
# apply the int.ltmleMSM function. In order to apply the TMLE and IPTW estimators,
# gcomp argument is set to FALSE.
cont.interaction <- int.ltmleMSM(data = df.cont.Y,
Qform = Q_formulas,
gform = g_formulas,
Anodes = c("sex", "env"),
Lnodes = c("conf1", "conf2", "conf3"),
Ynodes = c("hlth.outcome"),
SL.library = SL.library,
gcomp = FALSE,
iptw.only = FALSE,
survivalOutcome = FALSE,
variance.method = "ic")
cont.interaction$ltmle_MSM$transformOutcome
cont.interaction$ltmle_MSM$transformOutcome[1]
cont.interaction$ltmle_MSM$transformOutcome[2]
cont.interaction$ltmle_MSM$transformOutcome[3]
class(cont.interaction$ltmle_MSM$transformOutcome)
cont.interaction$ltmle_MSM$transformOutcome[[1]]
cont.interaction$ltmle_MSM$transformOutcome[[2]]
cont.interaction$ltmle_MSM$transformOutcome[[3]]
attribute(cont.interaction$ltmle_MSM$transformOutcome)
?base::atr
?base::attr
attr(cont.interaction$ltmle_MSM$transformOutcome, "Yrange")
continuous.interaction <- int.ltmleMSM(data = df.cont.Y,
Qform = Q_formulas,
gform = g_formulas,
Anodes = c("sex", "env"),
Lnodes = c("conf1", "conf2", "conf3"),
Ynodes = c("hlth.outcome"),
SL.library = SL.library,
gcomp = FALSE,
iptw.only = FALSE,
survivalOutcome = FALSE,
variance.method = "ic")
continuous.interaction$ltmle_MSM$transformOutcome
attr(continuous.interaction$ltmle_MSM$transformOutcome, "Yrange")
continuous.interaction$ltmle_MSM$msm
continuous.interaction$ltmle_MSM$msm$family
continuous.interaction$ltmle_MSM$msm$coefficients
load_all()
rm(list=ls())
param.causal.model <- function(p_L1 = 0.50, p_L2 = 0.20, p_L3 = 0.70,  # baseline confounders
b_A1 = 0.10, b_L1_A1 = 0.15, b_L2_A1 = 0.25,  # exposure A1
b_A2 = 0.15, b_L1_A2 = 0.20, b_L3_A2 = 0.20,  # exposure A2
Y_type = "binary", # or "continuous"
b_Y = 0.10,   # outcome Y
b_L1_Y = 0.02,
b_L2_Y = 0.02,
b_L3_Y = -0.02,
b_A1_Y = 0.3,
b_A2_Y = 0.1,
b_A1A2_Y = 0.4,
se_Y = NULL) {  # b_A1A2_Y is the interaction effect A1 * A2 -> Y
# check the sum of A1 parameters is not greater than 100%
try(if(b_A1 + b_L1_A1 + b_L1_A1 > 1)
stop("The sum of parameters to simulate A1 should not be greater than 100%"))
# check the sum of A2 parameters is not greater than 100%
try(if(b_A2 + b_L1_A2 + b_L3_A2 > 1)
stop("The sum of parameters to simulate A2 should not be greater than 100%"))
if (Y_type == "binary") {
# check the sum of Y parameters is not greater than 100% nor less than 0%
try(if(b_Y + b_L1_Y + b_L2_Y + b_L3_Y + b_A1_Y + b_A2_Y + b_A1A2_Y > 1)
stop("The sum of parameters to simulate Y should not be greater than 100%"))
try(if(b_Y + b_L1_Y + b_L2_Y + b_L3_Y + b_A1_Y + b_A2_Y + b_A1A2_Y < 0)
stop("The sum of parameters to simulate Y should not be less than 0%"))
try(if(!is.null(se_Y))
stop("se_Y should be NULL for binary outcomes Y"))
}
if (Y_type == "continuous") {
try(if(is.null(se_Y))
stop("se_Y should not be NULL for continuous outcomes Y"))
}
coef <- list(c(p_L1 = p_L1, p_L2 = p_L2, p_L3 = p_L3),
c(b_A1 = b_A1, b_L1_A1 = b_L1_A1, b_L2_A1 = b_L2_A1),
c(b_A2 = b_A2, b_L1_A2 = b_L1_A2, b_L3_A2 = b_L3_A2),
c(b_Y = b_Y, b_L1_Y = b_L1_Y, b_L2_Y = b_L2_Y, b_L3_Y = b_L3_Y,
b_A1_Y = b_A1_Y, b_A2_Y = b_A2_Y, b_A1A2_Y = b_A1A2_Y),
c(se_Y = se_Y))
return(coef)
}
generate.data <- function(N, b =  param.causal.model(), Y_type = "binary") {
conf1 <- rbinom(N, size = 1, prob = b[[1]]["p_L1"])
conf2 <- rbinom(N, size = 1, prob = b[[1]]["p_L2"])
conf3 <- rbinom(N, size = 1, prob = b[[1]]["p_L3"])
sex <- rbinom(N, size = 1, prob = b[[2]]["b_A1"] +
(b[[2]]["b_L1_A1"] * conf1) + (b[[2]]["b_L2_A1"] * conf2))
env <- rbinom(N, size = 1, prob = b[[3]]["b_A2"] +
(b[[3]]["b_L1_A2"] * conf1) + (b[[3]]["b_L3_A2"] * conf3))
if (Y_type == "binary") {
hlth.outcome <- rbinom(N, size = 1, prob = (b[[4]]["b_Y"] +
(b[[4]]["b_L1_Y"] * conf1) +
(b[[4]]["b_L2_Y"] * conf2) +
(b[[4]]["b_L3_Y"] * conf3) +
(b[[4]]["b_A1_Y"] * sex) +
(b[[4]]["b_A2_Y"] * env) +
(b[[4]]["b_A1A2_Y"] * sex * env)) )
}
if (Y_type == "continuous") {
hlth.outcome <- rnorm(N, mean = (b[[4]]["b_Y"] +
(b[[4]]["b_L1_Y"] * conf1) +
(b[[4]]["b_L2_Y"] * conf2) +
(b[[4]]["b_L3_Y"] * conf3) +
(b[[4]]["b_A1_Y"] * sex) +
(b[[4]]["b_A2_Y"] * env) +
(b[[4]]["b_A1A2_Y"] * sex * env)),
sd = b[[5]]["se_Y"])
}
data.sim <- data.frame(conf1, conf2, conf3, sex, env, hlth.outcome)
return(data.sim)
}
set.seed(54321)
df.cont.Y <- generate.data(N = 1000,
b = param.causal.model(Y_type = "continuous",
b_Y = 100, b_L1_Y = 10, b_L2_Y = 30,
b_L3_Y = -20, b_A1_Y = 10, b_A2_Y = 30,
b_A1A2_Y = 20, se_Y = 20),
Y_type = "continuous")
summary(df.cont.Y)
Q_formulas = c(hlth.outcome="Q.kplus1 ~ conf1 + conf2 + conf3 + sex * env")
g_formulas = c("sex ~ conf1 + conf2","env ~ conf1 + conf3")
# choose a set of fitting libraries to pass to SuperLearner:
SL.library = list(Q=list("SL.glm"),g=list("SL.glm"))
# apply the int.ltmleMSM function. In order to apply the TMLE and IPTW estimators,
# gcomp argument is set to FALSE.
continuous.interaction <- int.ltmleMSM(data = df.cont.Y,
Qform = Q_formulas,
gform = g_formulas,
Anodes = c("sex", "env"),
Lnodes = c("conf1", "conf2", "conf3"),
Ynodes = c("hlth.outcome"),
SL.library = SL.library,
gcomp = FALSE,
iptw.only = FALSE,
survivalOutcome = FALSE,
variance.method = "ic")
continuous.interaction
continuous.interaction$ltmle_MSM$transformOutcome
attr(continuous.interaction$ltmle_MSM$transformOutcome, "Yrange")
# The parameters of the MSM are estimated on the logit scale
continuous.interaction$ltmle_MSM$msm$family
# where the coefficients beta_0, beta_A1, beta_A2, and beta_A1_A2 are respectively
continuous.interaction$ltmle_MSM$msm$coefficients
rm(list=ls())
load_all()
param.causal.model <- function(p_L1 = 0.50, p_L2 = 0.20, p_L3 = 0.70,  # baseline confounders
b_A1 = 0.10, b_L1_A1 = 0.15, b_L2_A1 = 0.25,  # exposure A1
b_A2 = 0.15, b_L1_A2 = 0.20, b_L3_A2 = 0.20,  # exposure A2
Y_type = "binary", # or "continuous"
b_Y = 0.10,   # outcome Y
b_L1_Y = 0.02,
b_L2_Y = 0.02,
b_L3_Y = -0.02,
b_A1_Y = 0.3,
b_A2_Y = 0.1,
b_A1A2_Y = 0.4,
se_Y = NULL) {  # b_A1A2_Y is the interaction effect A1 * A2 -> Y
# check the sum of A1 parameters is not greater than 100%
try(if(b_A1 + b_L1_A1 + b_L1_A1 > 1)
stop("The sum of parameters to simulate A1 should not be greater than 100%"))
# check the sum of A2 parameters is not greater than 100%
try(if(b_A2 + b_L1_A2 + b_L3_A2 > 1)
stop("The sum of parameters to simulate A2 should not be greater than 100%"))
if (Y_type == "binary") {
# check the sum of Y parameters is not greater than 100% nor less than 0%
try(if(b_Y + b_L1_Y + b_L2_Y + b_L3_Y + b_A1_Y + b_A2_Y + b_A1A2_Y > 1)
stop("The sum of parameters to simulate Y should not be greater than 100%"))
try(if(b_Y + b_L1_Y + b_L2_Y + b_L3_Y + b_A1_Y + b_A2_Y + b_A1A2_Y < 0)
stop("The sum of parameters to simulate Y should not be less than 0%"))
try(if(!is.null(se_Y))
stop("se_Y should be NULL for binary outcomes Y"))
}
if (Y_type == "continuous") {
try(if(is.null(se_Y))
stop("se_Y should not be NULL for continuous outcomes Y"))
}
coef <- list(c(p_L1 = p_L1, p_L2 = p_L2, p_L3 = p_L3),
c(b_A1 = b_A1, b_L1_A1 = b_L1_A1, b_L2_A1 = b_L2_A1),
c(b_A2 = b_A2, b_L1_A2 = b_L1_A2, b_L3_A2 = b_L3_A2),
c(b_Y = b_Y, b_L1_Y = b_L1_Y, b_L2_Y = b_L2_Y, b_L3_Y = b_L3_Y,
b_A1_Y = b_A1_Y, b_A2_Y = b_A2_Y, b_A1A2_Y = b_A1A2_Y),
c(se_Y = se_Y))
return(coef)
}
generate.data <- function(N, b =  param.causal.model(), Y_type = "binary") {
conf1 <- rbinom(N, size = 1, prob = b[[1]]["p_L1"])
conf2 <- rbinom(N, size = 1, prob = b[[1]]["p_L2"])
conf3 <- rbinom(N, size = 1, prob = b[[1]]["p_L3"])
sex <- rbinom(N, size = 1, prob = b[[2]]["b_A1"] +
(b[[2]]["b_L1_A1"] * conf1) + (b[[2]]["b_L2_A1"] * conf2))
env <- rbinom(N, size = 1, prob = b[[3]]["b_A2"] +
(b[[3]]["b_L1_A2"] * conf1) + (b[[3]]["b_L3_A2"] * conf3))
if (Y_type == "binary") {
hlth.outcome <- rbinom(N, size = 1, prob = (b[[4]]["b_Y"] +
(b[[4]]["b_L1_Y"] * conf1) +
(b[[4]]["b_L2_Y"] * conf2) +
(b[[4]]["b_L3_Y"] * conf3) +
(b[[4]]["b_A1_Y"] * sex) +
(b[[4]]["b_A2_Y"] * env) +
(b[[4]]["b_A1A2_Y"] * sex * env)) )
}
if (Y_type == "continuous") {
hlth.outcome <- rnorm(N, mean = (b[[4]]["b_Y"] +
(b[[4]]["b_L1_Y"] * conf1) +
(b[[4]]["b_L2_Y"] * conf2) +
(b[[4]]["b_L3_Y"] * conf3) +
(b[[4]]["b_A1_Y"] * sex) +
(b[[4]]["b_A2_Y"] * env) +
(b[[4]]["b_A1A2_Y"] * sex * env)),
sd = b[[5]]["se_Y"])
}
data.sim <- data.frame(conf1, conf2, conf3, sex, env, hlth.outcome)
return(data.sim)
}
param.causal.model
rm(list=ls())
library(usethis)
library(devtools)
load_all(./R)
load_all("./R")
load_all("./R", TRUE)
